# Языки программирования для работы с большими данными


[План. 2024, весна. Заочное.](plans/2024_distance_plan.md)


## Содержание
### Основы Java
1. О курсе. Основы языка программирования Java. Примеры использования технологий BigData. Типы данных в Java. Работа со строками и числами.  Структура JVM
   - https://docs.google.com/presentation/d/1pmOlWlulw2prFhPjn73f3SE6KCyYtW2jYux-aKugVcA/edit?usp=sharing
   - Pattern Matching: https://github.com/VetrovSV/OOP/blob/master/examples/java/pattern_matching.md 
2. Структура памяти. Сборщик мусора. Строки. Интернирование строк. Методы. Числа. Библиотека коллекций в Java. Юнит тестирование JUnit. Альтернативная библиотека коллекций в Java: Apache Commons Collections & Google Guava. Примеры. https://docs.google.com/presentation/d/1Td-9ajaiMqHK_dGIjq2enU0MZdtbDoB7s-46NyuGtq4/edit?usp=sharing
3. Потоки в Java. Класс Thread, интерфейс Runnable. Ключевое слово synchronized. Пулы потоков.
   - https://github.com/ivtipm/BigDataLanguages/tree/main/Java/Threads
   - Сборщик Maven. Ввод и вывод в Java. Классы: InputStream, Outputstream, Scanner, BufferedReader. Исключения. Stream API
4. Stream API.
- Понятие потока (stream). Терминальные и промежуточные потоки, их методы. Специальные потоки. Генераторы. Параллельная обработка данных в потоках (multithreading).
https://github.com/ivtipm/BigDataLanguages/blob/main/Java/Streams/readme.md

### Системы хранения и обработки данных, Scala
1. Работа с базами данных в Java. Введение в язык Scala – ООП и переменные, Scala Shell, коллекции в Scala
   - https://ivtipm.github.io/BigDataLanguages/Scala/slides/Scala_about.html
   - [Шпаргалка](Scala/Readme.md)
1. Примеры Pattern matching; ScalikeJDBC - библиотека для работы с реляционными БД в Scala; SCOPT - библиотека по разбору командной строки
1. Apache Spark, запуск и форматы данных: plain text storage, sequence files, parquet, orc, avro. 
1. Работы с вводом-выводом. Задачи на Stream API


## Задания
### 1. Основы Java. 
#### Задание 1. Скрапер
Скачайте заголовки новостей\постов как минимум со 100 страниц новостного сайта, телеграм-канала, сообщества социальной сети и т.п.
Можно использовать новости с сайта zabgu.ru (вероятно он изменится в феврале-марте 2024 года).
   - Компилируйте и запускайте программу в консоли.
      - Передавайте количество страниц для скачивания, файл для сохранения заголовков через аргументы командной строки
      - В комментариях укажите команду компиляции и запуска
   - Дополнительные баллы за
     - скачивание метаданных (дата, теги, количество просмотров, лайков, реакций и т.п.)
     - скачивание текста статьи или новости
     - скачивание картинок
     - передачу данных в программу через аргументы командной строки (количество страниц или новостей для скачивания, имя файла для сохранения новостей и т.п.)
   - Сохраняйте данные в CSV файл
   - Предусмотрите возможность задать интервал (возможно случайный) между запросами страницы.
   - Документируйте код, пишите пояснения.
   

**Подсказки**
* Как скачать веб-страницу: https://github.com/ivtipm/BigDataLanguages/blob/main/Java/requests.md
   https://mkyong.com/java/java-how-to-download-web-page-from-internet/ 
* сервер может не выдавать страницы если не указан UserAgent.
* указывайте большое время ожидания (timeout) для чтобы иметь больше гарантий на получение страницы целиком
* если есть опасность блокировки множественных запросов, то делайте перерыв между запросами


### 2. Строки и текст
Что-то с регулярными выражениями, StringBuilder, Formatter
- Слайды: https://docs.google.com/presentation/d/1pmOlWlulw2prFhPjn73f3SE6KCyYtW2jYux-aKugVcA/edit#slide=id.g1b63e56b075_0_77
- Примеры работы с регулярными выражениями: https://github.com/ivtipm/BigDataLanguages/blob/main/Java/strings.md

#### Задание 2. Анализ текста
Дополните программу из предыдущего задания:
1. Скачивайте тексты новостей
2. Проанализируйте скаченные тексты:
    - найдите упоминания людей, названий вузов, факультетов или ищите другие сущности
    - подсчитайте частоты упоминаемых имён 
    
    
**Подсказки**
- https://regex101.com -- для экспериментов с регулярными выражениями

### 3. Коллекции
Списки, множества и словари

### 4. Многопоточность
Многопоточность с синхронизацией.
https://github.com/ivtipm/BigDataLanguages/blob/main/Java/Threads/readme.md

#### Задание 3. Многопоточность.
Создайте многопоточную версию программы из задания 1.
Используйте пул потоков. 
Используйте потоки, в первую очередь, для оптимизации узких мест.\
Действуйте так, чтобы избежать блокировки на ресурсе, откуда скачиваете новости.


### 5. Взаимодействие с СУБД
- https://github.com/ivtipm/BigDataLanguages/tree/main/Java/DataBase

#### Задание 4. Взаимодействие с БД
Модифицируйте программу из прошлого задания. Записывайте данные в БД на выбор: SQLite, Postgres, MySql, свой вариант, в том числе noSql БД.

*Бонус: Создайте общую таблицу для группы на общей БД. Адрес и данные для доступа есть у старосты или преподавателя (upd 31 mar: порт обновился). Сделайте таблицу такой, чтобы она подошла всем, кто скачивает новости.*

*Бонус: Создайте отдельных пользователей с правами доступа только к таблице.*

*Бонус: Добавьте в свою программу возможность сохранять данные в эту БД или экспортируйте в неё уже скаченные данные*



#### Задание 5. Stream API
Создайте вариант программы из предыдущих заданий, который использует Stream API для скачивания и обработки данных.
- Конспект: https://github.com/ivtipm/BigDataLanguages/tree/main/Java/Streams



### 6. Основы Scala
Знакомство с базовым синтаксисом Scala: переменные, значения, типы; функции, анонимные функции; классы, объекты; интерфейсы и трейты; особенности и отличия от Java
- https://ivtipm.github.io/BigDataLanguages/Scala/slides/Scala_about.html
- [Шпаргалка](Scala/Readme.md)

#### Задание 6. Scala
- Установите компилятор Scala. Попробуйте запустить примеры кода из лекции.
- Установите Apache Spark.
- Выполните задачи из строк 11, 19 и 23 [задачника](https://ivtipm.github.io/Programming/Files/spisocall.htm).  Пишите функции. Пишите тесты. Разбивайте код на модули.

#### Задание 7. Scala. Обработка данных
Напишите программу, которая подсчитывает количество появлений каждого IP адреса и логина в файле лога (см. дискорд).
Используйте коллекции.
Результат выводите в другой файл. Имя входного и выходного параметра задавайте через параметры командной строки.

*Можно предложить свой вариант задания*




### 7. Apache Spark - 1
Apache Spark. Настройка и работа c REPL.
- https://ivtipm.github.io/BigDataLanguages/Spark/slides/Spark.html
- https://github.com/ivtipm/BigDataLanguages/blob/main/Spark/Spark.md


### Задание Spark
1. Войдите на сервер, где установлен Spark
   - Проверьте версию Spark
   - Убедитесь, что задана переменная окружения SPARK_HOME
   - Убедитесь, что spark shell работает
   - Запустите тестовую программу из отдельного файла
   - Запустите Apache Zeppelin; подключитесь к оболочке через браузер
2. Сделайте короткую шапаргалку с основами работы в терминале
   - Перемещение по директориям, операции с файлами и папаками
   - Информация о аппаратном обеспечении
   - Монитор процессов
   - tmux
   - grep
   - wget
3. Запустите кластер [в докер контейнерах]

### 8. Apache Spark - 2
Resilient Distributed Dataset

### Задание Spark 
Допишите ноутбук `zeppelin_notebook.zpln`, решающий задачу классификации. Дополните коментариями.\
https://github.com/ivtipm/BigDataLanguages/tree/main/Spark


## Рубежный контроль
1. Программирование на Java. Потоки (stream) и потоки (thread) на Java. (35 баллов)
2. Программирование на Scala. (35 баллов)


## Экзамен
2 вопроса: теория + практика (20 + 10 баллов)
